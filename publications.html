<!DOCTYPE html>
<!-- saved from url=(0039)http://www.cbsr.ia.ac.cn/users/sfzhang/ -->
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1.0">
  <meta name="author" content="yangxue">
  <title>Xue Yang's Homepage</title>

  <!-- CSS  -->
  <link href="./files/materialize.min.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/aos.css" type="text/css" rel="stylesheet" media="screen,projection">
  <link href="./files/style.css" type="text/css" rel="stylesheet" media="screen,projection">

  <link rel="shortcut icon" href="./images/yangxue1.jpeg">
<script type="text/javascript" src="./files/jquery-1.12.4.min.js.下载"></script><style>@-moz-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-webkit-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@-o-keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}@keyframes nodeInserted{from{opacity:0.99;}to{opacity:1;}}embed,object{animation-duration:.001s;-ms-animation-duration:.001s;-moz-animation-duration:.001s;-webkit-animation-duration:.001s;-o-animation-duration:.001s;animation-name:nodeInserted;-ms-animation-name:nodeInserted;-moz-animation-name:nodeInserted;-webkit-animation-name:nodeInserted;-o-animation-name:nodeInserted;}</style></head>
<body data-aos-easing="ease" data-aos-duration="400" data-aos-delay="0">
  
  <div class="navbar-fixed">

    <nav class="white">
      <div class="nav-wrapper container"><a id="logo-container" href="https://yangxue0827.github.io/#" class="brand-logo"></a>
        <ul class="left">
          <li><a class="nav-item waves-effect waves-light active" href="https://yangxue0827.github.io/#home">Home</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#biography">Biography</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#news">News</a></li>
          <!-- <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#preprints">Preprints</a></li> -->
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#projects">Projects</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#activities">Activities</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#education">Education</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#internship">Internship</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#awards">Awards</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#publications">Publications</a></li>
          <li><a class="nav-item waves-effect waves-light" href="https://yangxue0827.github.io/#demos">Demos</a></li>
        </ul>
        </ul>

      </div>
    </nav>
  </div>
  

<!--==========================================
                   Publications
===========================================-->
<div class="section publications-section scrollspy" id="publications">

  <div class="row container">
    <div class="row">
      <div class="title">Publications</div>
      <hr>
    </div>

    <font color="blue"><b>(* indicates equal contribution)</b></font>

    <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./images/mmrotate.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">MMRotate: A Rotated Object Detection Benchmark using PyTorch</div>
            <div class="paper-author">Yue Zhou<sup>*</sup>, <font color="#0000dd"><b>Xue Yang<sup>*</sup></b></font>, Gefan Zhang, Jiabao Wang, Yanyi Liu, Liping Hou, Xue Jiang, Xingzhao Liu, Junchi Yan, Chengqi Lyu, Wenwei Zhang, Kai Chen</div>
            <div class="paper-conf">In <em>Proceedings of the 30th ACM International Conference on Multimedia <font color="red"><b>(ACM MM, CCF-A)</b></font></em>, Lisboa, Portugal, Open Source Software Competition, 2022</div> 
            <div>
              <a href="https://arxiv.org/abs/2204.13317" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2204.13317-B31B1B.svg" /></a>
              <a href="https://www.semanticscholar.org/paper/MMRotate%3A-A-Rotated-Object-Detection-Benchmark-Zhou-Yang/3df973b157132c46f299787d2c5852059d6ce68b" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F3df973b157132c46f299787d2c5852059d6ce68b%3Ffields%3DcitationCount" /></a>
            </div>
            <div>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[MMRotate]</a>
          </div>
          </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/rsdet++.jpg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">RSDet++: Point-based Modulated Loss for More Accurate Rotated Object Detection</div>
          <div class="paper-author">Wen Qian, <font color="#0000dd"><b>Xue Yang</b></font>, Silong Peng, Junchi Yan, Xiujuan Zhang</div>
          <div class="paper-conf"><em>IEEE Transactions on Circuits and Systems for Video Technology <font color="red"><b>(TCSVT, CCF-B)</b></font></em>, 2022</div>

          <!-- <div> -->
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <!-- <a href="https://arxiv.org/abs/1911.08299" target="_blank">paper</a> -->
          <!-- </div> -->
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2109.11906" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2109.11906-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/RSDet%2B%2B%3A-Point-based-Modulated-Loss-for-More-Object-Qian-Yang/abb919ba0e98dfb64fb5f0b7556bf859da867dc6" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fabb919ba0e98dfb64fb5f0b7556bf859da867dc6%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[RSDet++-TF]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/scrdet++.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">SCRDet++: Detecting Small, Cluttered and Rotated Objects via Instance-Level Feature Denoising and Rotation Loss Smoothing</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan, Wenlong Liao, Xiaokang Yang, Jin Tang, Tao He</div>
          <div class="paper-conf"><em>IEEE Transactions on Pattern Analysis and Machine Intelligence <font color="red"><b>(TPAMI, CCF-A)</b></font></em>, 2022</div> 

          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2004.13316" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2004.13316-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/SCRDet%2B%2B%3A-Detecting-Small%2C-Cluttered-and-Rotated-Yang-Yan/881bb1d8062529a8a6e42b85345ce99f6bf93175" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F881bb1d8062529a8a6e42b85345ce99f6bf93175%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation?style=social" />
            <a href="https://github.com/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation" target="_blank">[IoU-Smooth L1 Loss-TF], </a>
            <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/DOTA-DOAI?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/DOTA-DOAI" target="_blank">[DOTA-DOAI]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/dataset2.jpeg">
            <a href="https://github.com/Thinklab-SJTU/S2TLD" target="_blank">[S<sup>2</sup>TLD]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/homepage.png">
            <a href="./SCRDet++.html" target="_blank">[project page]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/wwt_cvpr22.jpg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Dual-path Image Inpainting with Auxiliary GAN Inversion</div>
          <div class="paper-author">Wentao Wang, Li Niu, Jianfu Zhang, <font color="#0000dd"><b>Xue Yang</b></font>, Liqing Zhang</div>
          <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, New Orleans, Louisiana, USA, 2022</div> 
          <div>
            <a href="https://www.semanticscholar.org/paper/Dual-path-Image-Inpainting-with-Auxiliary-GAN-Wang-Niu/9e93ea471ade297fa55d836241428e2174d43fbe" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F9e93ea471ade297fa55d836241428e2174d43fbe%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://openaccess.thecvf.com/content/CVPR2022/html/Wang_Dual-Path_Image_Inpainting_With_Auxiliary_GAN_Inversion_CVPR_2022_paper.html" target="_blank">[paper], </a>
            <a href="./files/cvpr22_inp_poster.pdf" target="_blank">[poster]</a>
        </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/csl_gcl_ohdet.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">On the Arbitrary-Oriented Object Detection: Classification based Approaches Revisited</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan</div>
          <div class="paper-conf"><em>International Journal of Computer Vision <font color="red"><b>(IJCV, CCF-A)</b></font></em>, 2022</div> 

          <div>
            <a href="https://arxiv.org/abs/2003.05597" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2003.05597-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/On-the-Arbitrary-Oriented-Object-Detection%3A-Based-Yang-Yan/94e1b0fe4f00831e8afacc9bf684f1dc8ce39a77" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F94e1b0fe4f00831e8afacc9bf684f1dc8ce39a77%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/CSL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow" target="_blank">[CSL-TF], </a>
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/DCL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/DCL_RetinaNet_Tensorflow" target="_blank">[DCL-TF], </a>
            <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/OHDet_Tensorflow?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/OHDet_Tensorflow" target="_blank">[OHDet-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/dataset2.jpeg">
            <a href="OHD-SJTU.html" target="_blank">[OHD-SJTU]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/homepage.png">
            <a href="./CSL_GCL_OHDet.html" target="_blank">[project page]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/kld.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Learning High-Precision Bounding Box for Rotated Object Detection via Kullback-Leibler Divergence</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Xiaojiang Yang, Jirui Yang, Qi Ming, Wentao Wang, Qi Tian, Junchi Yan</div>
          <div class="paper-conf"><em>Advances in Neural Information Processing Systems <font color="red"><b>(NeurIPS, CCF-A)</b></font></em>, Virtual, 2021</div> 

          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2106.01883" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2106.01883-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/Learning-High-Precision-Bounding-Box-for-Rotated-Yang-Yang/81150a2746b1696482ca6fa7157e71b82c7ff530" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F81150a2746b1696482ca6fa7157e71b82c7ff530%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[KLD-TF], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[KLD-PyTorch]</a>
          </div>
           <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/kld_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/neurips21_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/380016283" target="_blank">[解读]</a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/bilibili.png"> -->
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" /></a>
            <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[视频解读]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
      <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <img class="responsive-img" src="./images/ril.png">
      </div>

      <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
        <div class="paper-title">Optimization for Arbitrary-Oriented Object Detection via Representation Invariance Loss</div>
        <div class="paper-author">Qi Ming, Lingjuan Miao, Zhiqiang Zhou, <font color="#0000dd"><b>Xue Yang</b></font>, Yunpeng Dong</div>
        <div class="paper-conf"><em>IEEE Geoscience and Remote Sensing Letters <font color="red"><b>(GRSL, CCF-C)</b></font></em>, 2021</div> 
        <!-- <div> -->
          <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
          <a href="https://arxiv.org/abs/2103.11636" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2103.11636-B31B1B.svg" /></a>
          <a href="https://www.semanticscholar.org/paper/Optimization-for-Arbitrary-Oriented-Object-via-Loss-Ming-Miao/d38b3d1f1d30b7669d991f02065fab9524fc9090" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fd38b3d1f1d30b7669d991f02065fab9524fc9090%3Ffields%3DcitationCount" /></a>
        <!-- </div> -->
        <div>
          <!-- <img class="responsive-img icon" src="./images/github.png"> -->
          <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
          <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[RIDet-TF], </a>
          <img src="https://img.shields.io/github/stars/ming71/RIDet?style=social" />
          <a href="https://github.com/ming71/RIDet" target="_blank">[RIDet-PyTorch]</a>
        </div>
      </div>
    </div>

    <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/pmrfnet.jpeg">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Parallel Multi-Resolution Fusion Network for Image Inpainting</div>
          <div class="paper-author">Wentao Wang, Jianfu Zhang, Li Niu, Haoyu Ling, <font color="#0000dd"><b>Xue Yang</b></font>, Liqing Zhang</div>
          <div class="paper-conf">In <em>Proceedings of the IEEE International Conference on Computer Vision <font color="red"><b>(ICCV, CCF-A)</b></font></em>, Virtual, 2021</div>
          <div>
            <a href="https://www.semanticscholar.org/paper/Parallel-Multi-Resolution-Fusion-Network-for-Image-Wang-Zhang/320335cd05e98089de35057348498000d3130429" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F320335cd05e98089de35057348498000d3130429%3Ffields%3DcitationCount" /></a>
          </div> 
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Wang_Parallel_Multi-Resolution_Fusion_Network_for_Image_Inpainting_ICCV_2021_paper.pdf" target="_blank">[paper], </a>
            <a href="./files/iccv21_wwt_poster.pdf" target="_blank">[poster]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/sla.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Sparse Label Assignment for Oriented Object Detection in Aerial Images</div>
          <div class="paper-author">Qi Ming,  Lingjuan Miao, Zhiqiang Zhou, Junjie Song, <font color="#0000dd"><b>Xue Yang</b></font></div>
          <div class="paper-conf">In <em>Remote Sensing</em>, 2021</div> 
          <div>
            <a href="https://www.semanticscholar.org/paper/Sparse-Label-Assignment-for-Oriented-Object-in-Ming-Miao/dd1f7e4da3868a4fa42324693f5b20c414bc5b7b" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdd1f7e4da3868a4fa42324693f5b20c414bc5b7b%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://www.mdpi.com/2072-4292/13/14/2664/htm" target="_blank">[paper]</a>
          </div>
          <div>
          <img src="https://img.shields.io/github/stars/ming71/SLA?style=social" />
          <a href="https://github.com/ming71/SLA" target="_blank">[SLA-PyTorch]</a>
        </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/gwd.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Rethinking Rotated Object Detection with Gaussian Wasserstein Distance Loss</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan, Qi Ming, Wentao Wang, Xiaopeng Zhang, Qi Tian</div>
          <div class="paper-conf">In <em>International Conference on Machine Learning <font color="red"><b>(ICML, CCF-A)</b></font></em>, Virtual, 2021</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2101.11952" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2101.11952-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/Rethinking-Rotated-Object-Detection-with-Gaussian-Yang-Yan/1b47ee25d1b078368813a417fbe73ceb290e4035" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1b47ee25d1b078368813a417fbe73ceb290e4035%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[GWD-TF], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[GWD-PyTorch]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/gwd_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/icml21_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/372357305" target="_blank">[解读]</a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/bilibili.png"> -->
            <img src="https://img.shields.io/badge/dynamic/json?label=views&style=social&logo=bilibili&query=data.stat.view&url=https%3A%2F%2Fapi.bilibili.com%2Fx%2Fweb-interface%2Fview%3Fbvid%3DBV1Wr4y1E7Qr" /></a>
            <a href="https://www.bilibili.com/video/BV1Wr4y1E7Qr" target="_blank">[视频解读]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/dcl.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Dense Label Encoding for Boundary Discontinuity Free Rotation Detection</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Liping Hou, Yue Zhou, Wentao Wang, Junchi Yan</div>
          <div class="paper-conf">In <em>Proceedings of the IEEE Computer Vision and Pattern Recognition <font color="red"><b>(CVPR, CCF-A)</b></font></em>, Virtual, 2021</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/2011.09670" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2011.09670-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/Dense-Label-Encoding-for-Boundary-Discontinuity-Yang-Hou/729559024cc246c4bb7b33e395d2957b27662eb4" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F729559024cc246c4bb7b33e395d2957b27662eb4%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/DCL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/DCL_RetinaNet_Tensorflow" target="_blank">[RetinaNet-DCL-TF], </a>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[R<sup>3</sup>Det-DCL-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/dcl_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/cvpr21_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/354373013" target="_blank">[解读]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

    <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/rsdet.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Learning Modulated Loss for Rotated Object Detection</div>
          <div class="paper-author">Wen Qian, <font color="#0000dd"><b>Xue Yang</b></font>, Silong Peng, Junchi Yan, Yue Guo</div>
          <div class="paper-conf">In <em>Proceedings of the Thirty-Five AAAI Conference on Artificial Intelligence <font color="red"><b>(AAAI, CCF-A)</b></font></em>, Vancouver, Canada (Virtual), 2021</div>

          <!-- <div> -->
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <!-- <a href="https://arxiv.org/abs/1911.08299" target="_blank">paper</a> -->
          <!-- </div> -->
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1911.08299" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1911.08299-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/Learning-Modulated-Loss-for-Rotated-Object-Qian-Yang/7322a4580299b322223730ca714a0a951788853a" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7322a4580299b322223730ca714a0a951788853a%3Ffields%3DcitationCount" /></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="https://www.paperdigest.org/2022/02/most-influential-aaai-papers-2022-02/"><em><font color="red"><b>Most Influential AAAI'21 Paper, Top 10</b></font></em></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[RSDet-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/rsdet_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/aaai_2021_qw_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/108185873" target="_blank">[解读]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/r3det.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">R<sup>3</sup>Det: Refined Single-Stage Detector with Feature Refinement for Rotating Object</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan, Ziming Feng, Tao He</div>
          <div class="paper-conf">In <em>Proceedings of the Thirty-Five AAAI Conference on Artificial Intelligence <font color="red"><b>(AAAI, CCF-A)</b></font></em>, Vancouver, Canada (Virtual), 2021</div>

          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1908.05612" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1908.05612-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/R3Det%3A-Refined-Single-Stage-Detector-with-Feature-Yang-Liu/edada2363969e3929366df06aad8a8e9c73ba32f" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fedada2363969e3929366df06aad8a8e9c73ba32f%3Ffields%3DcitationCount" /></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="https://www.paperdigest.org/2022/02/most-influential-aaai-papers-2022-02/"><em><font color="red"><b>Most Influential AAAI'21 Paper, Top 1</b></font></em></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/R3Det_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/R3Det_Tensorflow" target="_blank">[R<sup>3</sup>Det-TF], </a>
            <!-- <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/r3det-on-mmdetection?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/r3det-on-mmdetection" target="_blank">[R<sup>3</sup>Det-PyTorch], </a>
            <img src="https://img.shields.io/github/stars/SJTU-Thinklab-Det/r3det-pytorch?style=social" />
            <a href="https://github.com/SJTU-Thinklab-Det/r3det-on-mmdetection" target="_blank">[R<sup>3</sup>Det-PyTorch], </a> -->
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[R<sup>3</sup>Det-PyTorch]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="./files/r3det_slides.pdf" target="_blank">[slides], </a>
            <a href="./files/aaai_2021_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/csl.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Arbitrary-Oriented Object Detection with Circular Smooth Label</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan</div>
          <div class="paper-conf">In <em>Proceedings of the European Conference on Computer Vision <font color="red"><b>(ECCV, CCF-B)</b></font></em>, Glasgow, Scotland, UK (Virtual), 2020</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://link.springer.com/chapter/10.1007/978-3-030-58598-3_40" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2003.05597-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/Arbitrary-Oriented-Object-Detection-with-Circular-Yang-Yan/feb6f9d7082d29dbf4d6c1bb70b404f7237298b6" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Ffeb6f9d7082d29dbf4d6c1bb70b404f7237298b6%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/Thinklab-SJTU/CSL_RetinaNet_Tensorflow?style=social" />
            <a href="https://github.com/Thinklab-SJTU/CSL_RetinaNet_Tensorflow" target="_blank">[CSL-RetinaNet-TF]</a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[CSL-RetinaNet-PyTorch]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <!-- <a href="https://arxiv.org/abs/2003.05597" target="_blank">paper,</a> -->
            <a href="./files/csl_slides.pdf" target="_blank">[slides]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/111493759" target="_blank">[解读]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/scrdet.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">SCRDet: Towards More Robust Detection for Small, Cluttered and Rotated Objects</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Jirui Yang, Junchi Yan, Yue Zhang, Tengfei Zhang, Zhi Guo, Sun Xian, Kun Fu</div>
          <div class="paper-conf">In <em>Proceedings of the IEEE International Conference on Computer Vision <font color="red"><b>(ICCV, CCF-A)</b></font></em>, Seoul, Korea, 2019</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1811.07126" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1811.07126-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/SCRDet%3A-Towards-More-Robust-Detection-for-Small%2C-Yang-Yang/456b8ae5dd6f8316c1fda46c5a8b4204c10ae320" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F456b8ae5dd6f8316c1fda46c5a8b4204c10ae320%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation?style=social" />
            <a href="https://github.com/DetectionTeamUCAS/RetinaNet_Tensorflow_Rotation" target="_blank">[IoU-Smooth L1 Loss-TF],</a>
            <img src="https://img.shields.io/github/stars/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow?style=social" />
            <a href="https://github.com/DetectionTeamUCAS/R2CNN-Plus-Plus_Tensorflow" target="_blank">[R<sup>2</sup>CNN++-TF]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <!-- <a href="https://arxiv.org/abs/1811.07126" target="_blank">paper,</a> -->
            <a href="./files/iccv_2019_yx_poster.pdf" target="_blank">[poster]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/107400817" target="_blank">[解读]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/bmvc2019.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Rethinking Classification and Localization for Cascade R-CNN</div>
          <div class="paper-author">Ang Li, <font color="#0000dd"><b>Xue Yang</b></font>, Chongyang Zhang</div>
          <div class="paper-conf">In <em>Proceedings of the 30th British Machine Vision Conference <font color="red"><b>(BMVC, CCF-C)</b></font></em>, Cardiff, Wales, UK, 2019</div>
          <div>
            <a href="https://www.semanticscholar.org/paper/Rethinking-Classification-and-Localization-for-Li-Yang/d92bd7f2c2d83b321b588f32d791122a7396adf7" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fd92bd7f2c2d83b321b588f32d791122a7396adf7%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1907.11914" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1907.11914-B31B1B.svg" /></a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/access.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Position detection and direction prediction for arbitrary-oriented ships via multitask rotation region convolutional neural network</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Hao Sun, Xian Sun, Menglong Yan, Zhi Guo, Kun Fu</div>
          <div class="paper-conf">In <em>IEEE Access</em>, 2018</div>
          <div>
            <a href="https://www.semanticscholar.org/paper/Position-Detection-and-Direction-Prediction-for-via-Yang-Sun/750bc0d2c9105a352001875127d796599a994886" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F750bc0d2c9105a352001875127d796599a994886%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://ieeexplore.ieee.org/abstract/document/8464244" target="_blank">[paper]</a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/R2CNN_HEAD_FPN_Tensorflow?style=social" />
            <a href="https://github.com/yangxue0827/R2CNN_HEAD_FPN_Tensorflow" target="_blank">[R<sup>2</sup>CNN_HEAD_FPN-TF]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/igarss.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Object Detection With Head Direction in Remote Sensing Images Based on Rotational Region CNN</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Kun Fu, Hao Sun, Xian Sun, Menglong Yan, Wenhui Diao, Zhi Guo</div>
          <div class="paper-conf">In <em>IEEE International Geoscience and Remote Sensing Symposium <font color="red"><b>(IGARSS)</b></font></em>, 2018</div>
          <div>
            <a href="https://www.semanticscholar.org/paper/Object-Detection-with-Head-Direction-in-Remote-on-Yang-Fu/812bf76426f7522049882ef6164e67c94a69618c" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F812bf76426f7522049882ef6164e67c94a69618c%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://ieeexplore.ieee.org/document/8518383" target="_blank">[paper]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/DCMSNN.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">A Densely Connected End-to-End Neural Network for Multiscale and Multiscene SAR Ship Detection</div>
          <div class="paper-author">Jiao Jiao, Yue Zhang, Hao Sun, <font color="#0000dd"><b>Xue Yang</b></font>, Xun Gao, Wen Hong, Kun Fu, Xian Sun</div>
          <div class="paper-conf">In <em>IEEE Access</em>, 2018</div>
          <div>
            <a href="https://www.semanticscholar.org/paper/A-Densely-Connected-End-to-End-Neural-Network-for-Jiao-Zhang/11272cb9f1f5921741803e0a5b9c7d9bc4d5f7bc" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F11272cb9f1f5921741803e0a5b9c7d9bc4d5f7bc%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/pdf.png">
            <a href="https://ieeexplore.ieee.org/abstract/document/8334534" target="_blank">[paper]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/rdfpn.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">Automatic Ship Detection in Remote Sensing Images from Google Earth of Complex Scenes Based on Multiscale Rotation Dense Feature Pyramid Networks</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Hao Sun, Kun Fu, Jirui Yang, Xian Sun, Menglong Yan, Zhi Guo</div>
          <div class="paper-conf">In <em>Remote Sensing</em>, 2018</div>
          <div>
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <a href="https://arxiv.org/abs/1806.04331" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A1806.04331-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/Automatic-Ship-Detection-in-Remote-Sensing-Images-Yang-Sun/dad0e3d7b1dc51196255ba220ed58ff29aa7c92b" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fdad0e3d7b1dc51196255ba220ed58ff29aa7c92b%3Ffields%3DcitationCount" /></a>
          </div>
          <div class="paper-award">
            <img class="responsive-img icon" src="./images/cup.png">
            <a href="http://apps.webofknowledge.com/"><em><font color="red"><b>ESI Highly Cited Papers</b></font></em></a>
          </div>
          <!-- <div> -->
            <!-- <img class="responsive-img icon" src="./images/pdf.png"> -->
            <!-- <a href="https://www.mdpi.com/2072-4292/10/1/132" target="_blank">paper</a> -->
          <!-- </div> -->
          <div>
            <!-- <img class="responsive-img icon" src="./images/github.png"> -->
            <img src="https://img.shields.io/github/stars/yangxue0827/R-DFPN_FPN_Tensorflow?style=social" />
            <a href="https://github.com/yangxue0827/R-DFPN_FPN_Tensorflow" target="_blank">[R-DFPN-TF]</a>
          </div>
        </div>
      </div>
      <hr class="publication-hr">
      <!-- <div align='right'> <a href="./publications.html" class="more" target="_blank"><i></i> <font color="#A9A9A9" size="2">LEARN MORE>></font> </a></div> -->
  </div>


</div>

<!--==========================================
                   Preprints
===========================================-->
<div class="section preprints-section scrollspy" id="preprints">

  <div class="row container">
    <div class="row">
      <div class="title">Preprints</div>
      <hr>
    </div>

      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./images/g-rep.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">G-Rep: Gaussian Representation for Arbitrary-Oriented Object Detection</div>
            <div class="paper-author">Liping Hou, Ke Lu, <font color="#0000dd"><b>Xue Yang</b></font>, Yuqiu Li, Jian Xue</div>
            <div>
              <a href="https://arxiv.org/abs/2205.11796" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2205.11796-B31B1B.svg" /></a>
              <a href="https://www.semanticscholar.org/paper/G-Rep%3A-Gaussian-Representation-for-Object-Detection-Hou-Lu/1fd0d6280fcf5ad1ce960b882cde5cad8eb0aa1d" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1fd0d6280fcf5ad1ce960b882cde5cad8eb0aa1d%3Ffields%3DcitationCount" /></a>
            </div>
            <div>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[G-Rep-PyTorch]</a>
          </div>
          </div>
      </div>

      <div class="row">
          <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
              <img class="responsive-img" src="./images/gten.png">
          </div>

          <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <div class="paper-title">A Glyph-driven Topology Enhancement Network for Scene Text Recognition</div>
            <div class="paper-author">Tongkun Guan, Chaochen Gu, Jingzheng Tu, <font color="#0000dd"><b>Xue Yang</b></font>, Qi Feng</div>
            <div>
              <a href="https://arxiv.org/abs/2203.03382" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2203.03382-B31B1B.svg" /></a>
              <a href="https://www.semanticscholar.org/paper/A-Glyph-driven-Topology-Enhancement-Network-for-Guan-Gu/1eb445c6ccb839002b22d6ba05a6d3a83aac8372" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F1eb445c6ccb839002b22d6ba05a6d3a83aac8372%3Ffields%3DcitationCount" /></a>
            </div>
          </div>
        </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/kfiou.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">The KFIoU Loss for Rotated Object Detection</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Yue Zhou, Gefan Zhang, Jirui Yang, Wentao Wang, Junchi Yan, Xiaopeng Zhang, Qi Tian</div>
          <div>
            <a href="https://arxiv.org/abs/2201.12558" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2201.12558-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/The-KFIoU-Loss-for-Rotated-Object-Detection-Yang-Zhou/be046653174b9e14c29387ed8e8168ae81c9b5c1" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2Fbe046653174b9e14c29387ed8e8168ae81c9b5c1%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[KFIoU-TF], </a>
            <img src="https://img.shields.io/github/stars/open-mmlab/mmrotate?style=social" />
            <a href="https://github.com/open-mmlab/mmrotate" target="_blank">[KFIoU-PyTorch]</a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/zhihu.png">
            <a href="https://zhuanlan.zhihu.com/p/463496550" target="_blank">[解读]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

      <div class="row">
        <div class="col s12 m12 l4 center aos-init aos-animate" data-aos="fade-right" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
            <img class="responsive-img" src="./images/projects.png">
        </div>

        <div class="col s12 m12 l8 aos-init aos-animate" data-aos="fade-left" data-aos-offset="100" data-aos-easing="ease-in-sine" data-aos-duration="500" data-aos-once="true">
          <div class="paper-title">AlphaRotate: A Rotation Detection Benchmark using TensorFlow</div>
          <div class="paper-author"><font color="#0000dd"><b>Xue Yang</b></font>, Junchi Yan</div>
          <div>
            <a href="https://arxiv.org/abs/2111.06677" target="_blank"><img src="http://img.shields.io/badge/cs.CV-arXiv%3A2111.06677-B31B1B.svg" /></a>
            <a href="https://www.semanticscholar.org/paper/AlphaRotate%3A-A-Rotation-Detection-Benchmark-using-Yang-Zhou/7f150cebfbdd2c3a8901a27641f308b34858ea80" target="_blank"><img src="https://img.shields.io/badge/dynamic/json?label=citation&query=citationCount&url=https%3A%2F%2Fapi.semanticscholar.org%2Fgraph%2Fv1%2Fpaper%2F7f150cebfbdd2c3a8901a27641f308b34858ea80%3Ffields%3DcitationCount" /></a>
          </div>
          <div>
            <img class="responsive-img icon" src="./images/docs.png">
            <a href="https://rotationdetection.readthedocs.io/" target="_blank">[docs]</a>
          </div>
          <div>
            <img src="https://img.shields.io/github/stars/yangxue0827/RotationDetection?style=social" />
            <a href="https://github.com/yangxue0827/RotationDetection" target="_blank">[AlphaRotate-TF]</a>
          </div>
        </div>
      </div>

      <hr class="publication-hr">

  </div>

</div>

<!--==========================================
                   Footer
===========================================-->
<footer class="page-footer grey lighten-2">
    <div class="row">
      <div class="widgetContainer" style="width:300px; margin: 0 auto;">        
        <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=080808&w=300&t=tt&d=yZcblN50sSwsCOVmEPYqkPD6Wo-RFHx0E2yb6Ktm_Wk&co=ffffff&ct=808080&cmo=3acc3a&cmn=ff5353'></script>
      </div>
    </div>
    <div class="footer-copyright center black-text">
      Copyright © Xue Yang 2020
    </div>  
</footer>

<!--  Scripts-->
<script src="./files/jquery-2.1.1.min.js"></script>
<script src="./files/materialize.js"></script>
<script src="./files/aos.js"></script>
<script src="./init.js"></script>

</div><div class="jvectormap-tip"></div></body></html>